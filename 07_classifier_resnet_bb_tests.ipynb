{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-10T08:56:30.075606Z",
     "start_time": "2023-05-10T08:56:30.072825Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, torch, torch.nn as nn, torchvision, matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import PIL.Image as Image\n",
    "import re\n",
    "import numpy as np\n",
    "import torchvision.transforms.v2 as transforms\n",
    "from torchvision import datapoints\n",
    "from torchvision.models import ResNet50_Weights\n",
    "from torchvision.models import resnet50\n",
    "from torchvision.transforms.v2 import functional as F\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "\n",
    "\n",
    "train_folder = 'images/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/3686 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "923fb1a11a4440eda5688edf4d3a7553"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "xmls_folder = 'annotations/annotations/xmls/'\n",
    "xmls_filenames=[]\n",
    "for filename in os.listdir(xmls_folder):\n",
    "    xmls_filenames.append(filename)\n",
    "\n",
    "# remove all files that are not xmls\n",
    "for filename in xmls_filenames:\n",
    "    if not filename.endswith('.xml'):\n",
    "        xmls_filenames.remove(filename)\n",
    "\n",
    "# read xmls and collect in dataframe\n",
    "df=pd.DataFrame(columns=['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax'])\n",
    "for filename in tqdm(xmls_filenames):\n",
    "    tree = ET.parse(xmls_folder+filename)\n",
    "    root = tree.getroot()\n",
    "    height = int(root.find(\"size\")[0].text)\n",
    "    width = int(root.find(\"size\")[1].text)\n",
    "    channels = int(root.find(\"size\")[2].text)\n",
    "    jpgname=root.find(\"filename\").text\n",
    "    for member in root.findall(\"object\"):\n",
    "        bndbox = member.find(\"bndbox\")\n",
    "        xmin = int(bndbox.find(\"xmin\").text)\n",
    "        ymin = int(bndbox.find(\"ymin\").text)\n",
    "        xmax = int(bndbox.find(\"xmax\").text)\n",
    "        ymax = int(bndbox.find(\"ymax\").text)\n",
    "        label = re.split('_', jpgname)\n",
    "        if len(label) == 2:\n",
    "            label = label[0]\n",
    "        else:\n",
    "            label = label[0]+\"_\"+label[1]\n",
    "        df.loc[len(df)] = [jpgname, width, height, label, xmin, ymin, xmax, ymax]\n",
    "# use column filename as index\n",
    "df.set_index('filename', inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T08:56:33.342821Z",
     "start_time": "2023-05-10T08:56:30.396391Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "                            width  height               class  xmin  ymin  \\\nfilename                                                                    \nBritish_Shorthair_10.jpg      350     233   British_Shorthair    83    29   \ngerman_shorthaired_119.jpg    500     500  german_shorthaired   128    22   \nenglish_setter_158.jpg        500     333      english_setter    97    35   \nSiamese_178.jpg               400     500             Siamese    32    18   \npomeranian_162.jpg            300     222          pomeranian    19    32   \n...                           ...     ...                 ...   ...   ...   \nenglish_setter_155.jpg        390     500      english_setter   312    80   \nBirman_181.jpg                333     500              Birman   153    14   \nnewfoundland_112.jpg          500     489        newfoundland    50    75   \npomeranian_147.jpg            300     297          pomeranian    91    33   \nSiamese_175.jpg               375     500             Siamese   236     1   \n\n                            xmax  ymax  \nfilename                                \nBritish_Shorthair_10.jpg     197   142  \ngerman_shorthaired_119.jpg   240   222  \nenglish_setter_158.jpg       304   199  \nSiamese_178.jpg              363   369  \npomeranian_162.jpg           123   129  \n...                          ...   ...  \nenglish_setter_155.jpg       465   260  \nBirman_181.jpg               416   257  \nnewfoundland_112.jpg         410   440  \npomeranian_147.jpg           246   214  \nSiamese_175.jpg              455   240  \n\n[3687 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>width</th>\n      <th>height</th>\n      <th>class</th>\n      <th>xmin</th>\n      <th>ymin</th>\n      <th>xmax</th>\n      <th>ymax</th>\n    </tr>\n    <tr>\n      <th>filename</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>British_Shorthair_10.jpg</th>\n      <td>350</td>\n      <td>233</td>\n      <td>British_Shorthair</td>\n      <td>83</td>\n      <td>29</td>\n      <td>197</td>\n      <td>142</td>\n    </tr>\n    <tr>\n      <th>german_shorthaired_119.jpg</th>\n      <td>500</td>\n      <td>500</td>\n      <td>german_shorthaired</td>\n      <td>128</td>\n      <td>22</td>\n      <td>240</td>\n      <td>222</td>\n    </tr>\n    <tr>\n      <th>english_setter_158.jpg</th>\n      <td>500</td>\n      <td>333</td>\n      <td>english_setter</td>\n      <td>97</td>\n      <td>35</td>\n      <td>304</td>\n      <td>199</td>\n    </tr>\n    <tr>\n      <th>Siamese_178.jpg</th>\n      <td>400</td>\n      <td>500</td>\n      <td>Siamese</td>\n      <td>32</td>\n      <td>18</td>\n      <td>363</td>\n      <td>369</td>\n    </tr>\n    <tr>\n      <th>pomeranian_162.jpg</th>\n      <td>300</td>\n      <td>222</td>\n      <td>pomeranian</td>\n      <td>19</td>\n      <td>32</td>\n      <td>123</td>\n      <td>129</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>english_setter_155.jpg</th>\n      <td>390</td>\n      <td>500</td>\n      <td>english_setter</td>\n      <td>312</td>\n      <td>80</td>\n      <td>465</td>\n      <td>260</td>\n    </tr>\n    <tr>\n      <th>Birman_181.jpg</th>\n      <td>333</td>\n      <td>500</td>\n      <td>Birman</td>\n      <td>153</td>\n      <td>14</td>\n      <td>416</td>\n      <td>257</td>\n    </tr>\n    <tr>\n      <th>newfoundland_112.jpg</th>\n      <td>500</td>\n      <td>489</td>\n      <td>newfoundland</td>\n      <td>50</td>\n      <td>75</td>\n      <td>410</td>\n      <td>440</td>\n    </tr>\n    <tr>\n      <th>pomeranian_147.jpg</th>\n      <td>300</td>\n      <td>297</td>\n      <td>pomeranian</td>\n      <td>91</td>\n      <td>33</td>\n      <td>246</td>\n      <td>214</td>\n    </tr>\n    <tr>\n      <th>Siamese_175.jpg</th>\n      <td>375</td>\n      <td>500</td>\n      <td>Siamese</td>\n      <td>236</td>\n      <td>1</td>\n      <td>455</td>\n      <td>240</td>\n    </tr>\n  </tbody>\n</table>\n<p>3687 rows Ã— 7 columns</p>\n</div>"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T08:56:33.344656Z",
     "start_time": "2023-05-10T08:56:33.342619Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "nicht jedes Bild ist annotiert, daher nur training mit den annotierten Bildern\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "def get_bbox_part(filename, part):\n",
    "    # convert to float\n",
    "    return df.loc[filename, part]\n",
    "\n",
    "# dict to convert label to label_idx\n",
    "classes=df['class'].unique()\n",
    "classes_idx={}\n",
    "for i, c in enumerate(classes):\n",
    "    classes_idx[c]=i\n",
    "\n",
    "def convert_tensor_to_image(tensor_image, bbox):\n",
    "    # convert tensor to image\n",
    "\n",
    "    # draw bounding box\n",
    "    image=draw_bounding_boxes(image, bbox)\n",
    "    return image\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T09:11:07.967440Z",
     "start_time": "2023-05-10T09:11:07.965307Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Tensor expected, got <class 'PIL.Image.Image'>",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[92], line 53\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m row \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m2\u001B[39m):\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m col \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m5\u001B[39m):\n\u001B[0;32m---> 53\u001B[0m         image\u001B[38;5;241m=\u001B[39m\u001B[43mconvert_tensor_to_image\u001B[49m\u001B[43m(\u001B[49m\u001B[43mxb\u001B[49m\u001B[43m[\u001B[49m\u001B[43mrow\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43mcol\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbbox\u001B[49m\u001B[43m[\u001B[49m\u001B[43mrow\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43mcol\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     54\u001B[0m         ax[row, col]\u001B[38;5;241m.\u001B[39mimshow(image\u001B[38;5;241m.\u001B[39mpermute(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m0\u001B[39m))\n\u001B[1;32m     55\u001B[0m         ax[row, col]\u001B[38;5;241m.\u001B[39mset_title(classes[yb[row\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m5\u001B[39m\u001B[38;5;241m+\u001B[39mcol]\u001B[38;5;241m.\u001B[39mitem()])\n",
      "Cell \u001B[0;32mIn[91], line 15\u001B[0m, in \u001B[0;36mconvert_tensor_to_image\u001B[0;34m(tensor_image, bbox)\u001B[0m\n\u001B[1;32m     13\u001B[0m image \u001B[38;5;241m=\u001B[39m transforms\u001B[38;5;241m.\u001B[39mToPILImage()(tensor_image)\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# draw bounding box\u001B[39;00m\n\u001B[0;32m---> 15\u001B[0m image\u001B[38;5;241m=\u001B[39m\u001B[43mdraw_bounding_boxes\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbbox\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m image\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch_ds/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch_ds/lib/python3.10/site-packages/torchvision/utils.py:195\u001B[0m, in \u001B[0;36mdraw_bounding_boxes\u001B[0;34m(image, boxes, labels, colors, fill, width, font, font_size)\u001B[0m\n\u001B[1;32m    193\u001B[0m     _log_api_usage_once(draw_bounding_boxes)\n\u001B[1;32m    194\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(image, torch\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[0;32m--> 195\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTensor expected, got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(image)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    196\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m image\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m!=\u001B[39m torch\u001B[38;5;241m.\u001B[39muint8:\n\u001B[1;32m    197\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTensor uint8 expected, got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mimage\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mTypeError\u001B[0m: Tensor expected, got <class 'PIL.Image.Image'>"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x500 with 10 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class PetDataset(Dataset):\n",
    "    def __init__(self, filenames, labels, transform=None):\n",
    "        self.filenames = filenames\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname=self.filenames[idx]\n",
    "        image = Image.open(train_folder+fname)\n",
    "        image = image.convert('RGB')\n",
    "        label = classes_idx[self.labels[idx]]\n",
    "        bbox=datapoints.BoundingBox([[get_bbox_part(fname, 'xmin'),\n",
    "                                    get_bbox_part(fname, 'ymin'),\n",
    "                                    get_bbox_part(self.filenames[idx], 'xmax'),\n",
    "                                    get_bbox_part(self.filenames[idx], 'ymax')]],\n",
    "                                    format=datapoints.BoundingBoxFormat.XYXY,\n",
    "                                    spatial_size=F.get_spatial_size(image))\n",
    "        if self.transform:\n",
    "            image, bbox = self.transform(image, bbox)\n",
    "        return image, label, bbox\n",
    "\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToImageTensor(),\n",
    "    # to float\n",
    "    transforms.ConvertImageDtype(torch.float32),\n",
    "    transforms.Resize((300, 300), antialias=True),\n",
    "    # horizontal flip\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    # jitter brightness, contrast and saturation\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    # randomly crop image\n",
    "    transforms.RandomCrop(224, pad_if_needed=True, padding_mode='reflect'),\n",
    "    # warp\n",
    "    transforms.RandomPerspective(distortion_scale=0.3, p=0.6),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "sample_dataset=PetDataset(df.iloc[:20].index, df.iloc[:20][\"class\"], transform=transform)\n",
    "sample_dataloader=DataLoader(sample_dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "# visualize a batch of images using the dataloader\n",
    "fig, ax = plt.subplots(2, 5, figsize=(10, 5))\n",
    "index=0\n",
    "for xb, yb, bbox in sample_dataloader:\n",
    "    for row in range(2):\n",
    "        for col in range(5):\n",
    "            image=convert_tensor_to_image(xb[row*5+col], bbox[row*5+col])\n",
    "            ax[row, col].imshow(image.permute(1, 2, 0))\n",
    "            ax[row, col].set_title(classes[yb[row*5+col].item()])\n",
    "            ax[row, col].axis('off')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T09:11:09.006179Z",
     "start_time": "2023-05-10T09:11:08.584840Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%debug"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-10T08:56:25.367427Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(filenames, labels, test_size=0.2, random_state=42, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T08:56:25.543499Z",
     "start_time": "2023-05-10T08:56:25.532544Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([10, 37])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# use a pretrained resnte50\n",
    "\n",
    "class OxfordPetsModel(nn.Module):\n",
    "    def __init__(self, p=0.2):\n",
    "        super().__init__()\n",
    "        self.resnet50=resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        self.resnet50.fc=nn.Sequential(\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(2048, 1000),\n",
    "            nn.BatchNorm1d(1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1000, 37)\n",
    "        )\n",
    "        for param in self.resnet50.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for param in self.resnet50.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return self.resnet50(xb)\n",
    "\n",
    "model=OxfordPetsModel()\n",
    "model(xb).shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T07:22:37.927974Z",
     "start_time": "2023-05-10T07:22:37.304181Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T07:22:37.945272Z",
     "start_time": "2023-05-10T07:22:37.943657Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def get_accuracy(model, loader):\n",
    "    correct=0\n",
    "    for xb, yb in loader:\n",
    "        xb=xb.to(device)\n",
    "        yb=yb.to(device)\n",
    "        y_hat=model(xb)\n",
    "        y_pred=torch.argmax(y_hat, dim=1)\n",
    "        correct+=(y_pred==yb).sum().item()\n",
    "    return correct/len(loader.dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T07:22:37.955782Z",
     "start_time": "2023-05-10T07:22:37.947745Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "\n",
    "train_dataset=PetDataset(X_train, y_train, transform=transform)\n",
    "test_dataset=PetDataset(X_test, y_test, transform=transform)\n",
    "train_loader=DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader=DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T07:22:37.955973Z",
     "start_time": "2023-05-10T07:22:37.949982Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "lr=0.01\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train_batch(model,optimizer,  xb, yb):\n",
    "    xb=xb.to(device)\n",
    "    yb=yb.to(device)\n",
    "    y_hat=model(xb)\n",
    "    loss = loss_fn(y_hat, yb)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    preds=torch.argmax(y_hat, dim=1)\n",
    "    return loss.item(), (preds==yb).sum().item()/len(yb)\n",
    "\n",
    "def train_epoch(model, optimizer,  x, y):\n",
    "    losses=[]\n",
    "    accs=[]\n",
    "    for xb, yb in train_loader:\n",
    "        loss, acc=train_batch(model, optimizer, xb, yb)\n",
    "        losses.append(loss)\n",
    "        accs.append(acc)\n",
    "    return losses, np.mean(accs), get_accuracy(model, test_loader)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T07:22:37.956093Z",
     "start_time": "2023-05-10T07:22:37.953959Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6c7356d0351142e6b075382ec4145b73"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[23], line 10\u001B[0m\n\u001B[1;32m      8\u001B[0m bar\u001B[38;5;241m=\u001B[39mtqdm(\u001B[38;5;28mrange\u001B[39m(EPOCHS))\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m bar:\n\u001B[0;32m---> 10\u001B[0m     losses, train_acc, test_acc\u001B[38;5;241m=\u001B[39m\u001B[43mtrain_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m     train_accs\u001B[38;5;241m.\u001B[39mappend(train_acc)\n\u001B[1;32m     12\u001B[0m     test_accs\u001B[38;5;241m.\u001B[39mappend(test_acc)\n",
      "Cell \u001B[0;32mIn[22], line 20\u001B[0m, in \u001B[0;36mtrain_epoch\u001B[0;34m(model, optimizer, x, y)\u001B[0m\n\u001B[1;32m     18\u001B[0m accs\u001B[38;5;241m=\u001B[39m[]\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m xb, yb \u001B[38;5;129;01min\u001B[39;00m train_loader:\n\u001B[0;32m---> 20\u001B[0m     loss, acc\u001B[38;5;241m=\u001B[39m\u001B[43mtrain_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mxb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43myb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m     losses\u001B[38;5;241m.\u001B[39mappend(loss)\n\u001B[1;32m     22\u001B[0m     accs\u001B[38;5;241m.\u001B[39mappend(acc)\n",
      "Cell \u001B[0;32mIn[22], line 12\u001B[0m, in \u001B[0;36mtrain_batch\u001B[0;34m(model, optimizer, xb, yb)\u001B[0m\n\u001B[1;32m     10\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m     11\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m---> 12\u001B[0m \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     13\u001B[0m preds\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39margmax(y_hat, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\u001B[38;5;241m.\u001B[39mitem(), (preds\u001B[38;5;241m==\u001B[39myb)\u001B[38;5;241m.\u001B[39msum()\u001B[38;5;241m.\u001B[39mitem()\u001B[38;5;241m/\u001B[39m\u001B[38;5;28mlen\u001B[39m(yb)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch_ds/lib/python3.10/site-packages/torch/optim/optimizer.py:280\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    276\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    277\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    278\u001B[0m                                \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbut got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 280\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    281\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[1;32m    283\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch_ds/lib/python3.10/site-packages/torch/optim/optimizer.py:33\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     32\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m---> 33\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     35\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(prev_grad)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch_ds/lib/python3.10/site-packages/torch/optim/adam.py:143\u001B[0m, in \u001B[0;36mAdam.step\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    132\u001B[0m     beta1, beta2 \u001B[38;5;241m=\u001B[39m group[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbetas\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m    134\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_group(\n\u001B[1;32m    135\u001B[0m         group,\n\u001B[1;32m    136\u001B[0m         params_with_grad,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    140\u001B[0m         max_exp_avg_sqs,\n\u001B[1;32m    141\u001B[0m         state_steps)\n\u001B[0;32m--> 143\u001B[0m     \u001B[43madam\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    144\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams_with_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    145\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    146\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    147\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    148\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    149\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    150\u001B[0m \u001B[43m        \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mamsgrad\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    152\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    153\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    154\u001B[0m \u001B[43m        \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mweight_decay\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    155\u001B[0m \u001B[43m        \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43meps\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    156\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmaximize\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    157\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforeach\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mforeach\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    158\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcapturable\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    159\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdifferentiable\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    160\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfused\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfused\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    161\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgrad_scale\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    162\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfound_inf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    163\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    165\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch_ds/lib/python3.10/site-packages/torch/optim/adam.py:283\u001B[0m, in \u001B[0;36madam\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[1;32m    280\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    281\u001B[0m     func \u001B[38;5;241m=\u001B[39m _single_tensor_adam\n\u001B[0;32m--> 283\u001B[0m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    284\u001B[0m \u001B[43m     \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    285\u001B[0m \u001B[43m     \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    286\u001B[0m \u001B[43m     \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    287\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    288\u001B[0m \u001B[43m     \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    289\u001B[0m \u001B[43m     \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamsgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    290\u001B[0m \u001B[43m     \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    291\u001B[0m \u001B[43m     \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    292\u001B[0m \u001B[43m     \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    293\u001B[0m \u001B[43m     \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    294\u001B[0m \u001B[43m     \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    295\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaximize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    296\u001B[0m \u001B[43m     \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcapturable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    297\u001B[0m \u001B[43m     \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdifferentiable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    298\u001B[0m \u001B[43m     \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgrad_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    299\u001B[0m \u001B[43m     \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfound_inf\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch_ds/lib/python3.10/site-packages/torch/optim/adam.py:395\u001B[0m, in \u001B[0;36m_single_tensor_adam\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001B[0m\n\u001B[1;32m    392\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    393\u001B[0m     denom \u001B[38;5;241m=\u001B[39m (exp_avg_sq\u001B[38;5;241m.\u001B[39msqrt() \u001B[38;5;241m/\u001B[39m bias_correction2_sqrt)\u001B[38;5;241m.\u001B[39madd_(eps)\n\u001B[0;32m--> 395\u001B[0m \u001B[43mparam\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maddcdiv_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexp_avg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdenom\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43mstep_size\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model = OxfordPetsModel().to(device)\n",
    "optimizer=torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "EPOCHS=20\n",
    "train_accs=[]\n",
    "test_accs=[]\n",
    "# define tqdm bar\n",
    "bar=tqdm(range(EPOCHS))\n",
    "for i in bar:\n",
    "    losses, train_acc, test_acc=train_epoch(model, optimizer, X_train, y_train)\n",
    "    train_accs.append(train_acc)\n",
    "    test_accs.append(test_acc)\n",
    "    bar.set_description(f\"Train Accuracy: {train_acc:.3f}, Test Accuracy: {test_acc:.3f}\")\n",
    "plt.plot(train_accs, label='train')\n",
    "plt.plot(test_accs, label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T07:26:03.699415Z",
     "start_time": "2023-05-10T07:22:37.957123Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bar=tqdm(range(EPOCHS))\n",
    "for i in bar:\n",
    "    losses, train_acc, test_acc=train_epoch(model, optimizer, X_train, y_train)\n",
    "    train_accs.append(train_acc)\n",
    "    test_accs.append(test_acc)\n",
    "    bar.set_description(f\"Train Accuracy: {train_acc:.3f}, Test Accuracy: {test_acc:.3f}\")\n",
    "plt.plot(train_accs, label='train')\n",
    "plt.plot(test_accs, label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
