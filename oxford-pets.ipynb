{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch, torch.nn as nn, torchvision, matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.io import read_image\n",
    "import PIL.Image as Image\n",
    "import re\n",
    "\n",
    "img_folder = '/Users/liam/Documents/Python/working/oxford-iiit-pet/images/'\n",
    "# ann_folder = '/Users/liam/Documents/Python/working/oxford-iiit-pet/annotations/annotations/trimaps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all files that are not images (jpg)\n",
    "for filename in os.listdir(img_folder):\n",
    "    if not filename.endswith('.jpg'):\n",
    "        os.remove(img_folder+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filenames=[]\n",
    "for filename in os.listdir(img_folder):\n",
    "    filenames.append(filename)\n",
    "    \n",
    "# get the labels from the image filenames via regular expressions\n",
    "# format: <class>_<color>_<number>.jpg\n",
    "# e.g. british_shorthair_100.jpg\n",
    "\n",
    "labels=[]\n",
    "for filename in filenames:\n",
    "    label = re.split('_', filename)\n",
    "    if len(label) == 2:\n",
    "        label = label[0]\n",
    "    else:\n",
    "        label = label[0]+\"_\"+label[1]\n",
    "    labels.append(label)\n",
    "\n",
    "# print unique labels\n",
    "print(set(labels))\n",
    "\n",
    "# count classes in labels\n",
    "from collections import Counter\n",
    "Counter(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = list(set(labels))\n",
    "classes_idx = {classes[i]:i for i in range(len(classes))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OxfordDataset(Dataset):\n",
    "    def __init__(self, filenames, labels, transform=None):\n",
    "        self.filenames = filenames\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            image = Image.open(img_folder+self.filenames[idx])\n",
    "            image = image.convert('RGB')\n",
    "            label = classes_idx[self.labels[idx]]\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, label\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"Error loading image: \", self.filenames[idx], \"idx\", idx)\n",
    "\n",
    "transform=torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Resize((224, 224), antialias=True),\n",
    "    torchvision.transforms.RandomHorizontalFlip(0.5),\n",
    "    torchvision.transforms.ColorJitter(brightness=0.05, contrast=0.1, saturation=0.05, hue=0.05),\n",
    "    # random erasing\n",
    "    torchvision.transforms.RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.3, 3.3), value=0, inplace=False),\n",
    "    torchvision.transforms.RandomRotation(degrees=10),\n",
    "])\n",
    "\n",
    "sample_dataset=OxfordDataset(filenames[:20], labels[:20], transform=transform)\n",
    "sample_dataloader=DataLoader(sample_dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "# visualize a batch of images using the dataloader\n",
    "fig, ax = plt.subplots(2, 5, figsize=(10, 5))\n",
    "index=0\n",
    "for xb, yb in sample_dataloader:\n",
    "    for row in range(2):\n",
    "        for col in range(5):\n",
    "            ax[row, col].imshow(xb[row*5+col].permute(1, 2, 0))\n",
    "            ax[row, col].set_title(classes[yb[row*5+col].item()])\n",
    "            ax[row, col].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(filenames, labels, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OxfordCNN(nn.Module):\n",
    "    def __init__(self, p=0.2):\n",
    "        super(OxfordCNN, self).__init__()\n",
    "        self.layer1=torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(32),\n",
    "            torch.nn.Dropout(p)\n",
    "        ) # 32x112x112\n",
    "        self.layer2=torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(32, 128, kernel_size=3, stride=2, padding=1),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(128),\n",
    "            torch.nn.Dropout(p)\n",
    "        ) # 128x28x28\n",
    "        self.layer3=torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(256),\n",
    "            torch.nn.Dropout(p)\n",
    "        ) # 256x7x7\n",
    "        self.layer4=torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(512),\n",
    "            torch.nn.Dropout(p)\n",
    "        ) # 512x2x2\n",
    "        self.fc1=torch.nn.Sequential(\n",
    "            torch.nn.Linear(512*2*2, 1000),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm1d(1000)\n",
    "        ) # 1000\n",
    "        self.fc2=torch.nn.Sequential(\n",
    "            torch.nn.Linear(1000, 2),\n",
    "            torch.nn.Softmax(dim=1)\n",
    "        ) # 2\n",
    "\n",
    "    def forward(self, xb):\n",
    "        out=self.layer1(xb) # 32x224x224\n",
    "        out=self.layer2(out) # 128x56x56\n",
    "        out=self.layer3(out) # 256x14x14\n",
    "        out=self.layer4(out) # 512x7x7\n",
    "        out=out.reshape(out.size(0), -1) # 512x2x2 -> 2048\n",
    "        out=self.fc1(out) # 1000\n",
    "        out=self.fc2(out) # 2\n",
    "        return out\n",
    "    \n",
    "model=OxfordCNN()\n",
    "model(xb).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, loader):\n",
    "    correct=0\n",
    "    #print('xb: '+type(xb)+', yb: '+type(yb)) -> throws reference error\n",
    "    for xb, yb in loader:\n",
    "        xb=xb.to(device)\n",
    "        yb=yb.to(device)\n",
    "        y_hat=model(xb)\n",
    "        y_pred=torch.argmax(y_hat, dim=1)\n",
    "        correct+=(y_pred==yb).sum().item()\n",
    "    return correct/len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# convert yb to one-hot encoding\n",
    "def one_hot(yb, num_classes):\n",
    "    yb_onehot=torch.zeros(yb.shape[0], num_classes)\n",
    "    yb_onehot[torch.arange(yb.shape[0]), yb]=1\n",
    "    return yb_onehot\n",
    "'''\n",
    "batch_size=128\n",
    "\n",
    "train_dataset=OxfordDataset(X_train, y_train, transform=transform)\n",
    "train_dataloader=DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset=OxfordDataset(X_test, y_test, transform=transform)\n",
    "test_dataloader=DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "p=0.2\n",
    "EPOCHS=10\n",
    "batch_size=10\n",
    "lr=0.01\n",
    "\n",
    "loss_fn=torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer=torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "def train_batch(model, optimizer, xb, yb):\n",
    "    xb=xb.to(device)\n",
    "    yb=yb.to(device)\n",
    "    y_hat=model(xb)\n",
    "    loss=loss_fn(y_hat, yb)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def train_epoch(model, optimizer,  x, y):\n",
    "    losses=[]\n",
    "    for xb, yb in train_dataloader:\n",
    "        losses.append(train_batch(model, optimizer, xb, yb))\n",
    "    return losses, get_accuracy(model, test_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OxfordCNN().to(device)\n",
    "optimizer=torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "accs=[]\n",
    "# define tqdm bar\n",
    "bar=tqdm(range(EPOCHS))\n",
    "for i in bar:\n",
    "    losses, acc=train_epoch(model, optimizer, X_train, y_train)\n",
    "    accs.append(acc)\n",
    "    bar.set_description(f\"Accuracy: {acc:.3f}\")\n",
    "plt.plot(accs) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
